{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "sent-analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pashatti/GlobalAIHubPythonHomework/blob/main/sent_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_cjWGN91y7H"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OXEEabF1y7L"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding, CuDNNGRU\n",
        "#from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq2XQ7KO1y7P"
      },
      "source": [
        "dataset = pd.read_csv('/content/sample_data/Test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bRlPl7LQ1y7P",
        "outputId": "014287ef-4355-4b61-f871-cf398e2d274c"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I always wrote this series off as being a comp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This movie was so poorly written and directed ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The most interesting thing about Miryang (Secr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>This is the kind of picture John Lassiter woul...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>A MUST SEE! I saw WHIPPED at a press screening...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>NBC should be ashamed. I wouldn't allow my chi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>This movie is a clumsy mishmash of various gho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Formula movie about the illegitimate son of a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     I always wrote this series off as being a comp...      0\n",
              "1     1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
              "2     This movie was so poorly written and directed ...      0\n",
              "3     The most interesting thing about Miryang (Secr...      1\n",
              "4     when i first read about \"berlin am meer\" i did...      0\n",
              "...                                                 ...    ...\n",
              "4995  This is the kind of picture John Lassiter woul...      1\n",
              "4996  A MUST SEE! I saw WHIPPED at a press screening...      1\n",
              "4997  NBC should be ashamed. I wouldn't allow my chi...      0\n",
              "4998  This movie is a clumsy mishmash of various gho...      0\n",
              "4999  Formula movie about the illegitimate son of a ...      0\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqeZ25qF1y7Q"
      },
      "source": [
        "target = dataset['label'].values.tolist()\n",
        "data = dataset['text'].values.tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRKhj2vj1y7R"
      },
      "source": [
        "cutoff = int(len(data) * 0.80)\n",
        "x_train, x_test = data[:cutoff], data[cutoff:]\n",
        "y_train, y_test = target[:cutoff], target[cutoff:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "imDWARC71y7S",
        "outputId": "17ddf07e-4248-4544-f34a-3d6e065a44f1"
      },
      "source": [
        "x_train[500]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Elizabeth Taylor never could act at all and she was just her usual annoying, untalented self in this film. This was before she got so fat but she still looked very short and dumpy. Rock Hudson was OK as Bick Benedict but clearly an actor with more range like William Holden would have been better. James Dean certainly proved he knew how to mumble his way through a movie. The whole film is incredibly slow and goes on for far too long. The actors were all too young and lightweight and none of them aged convincingly due to the poor make-up. Hudson looked ridiculous just being padded out and Dean and Carroll Baker were obviously the same age.<br /><br />0/10.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "5QsBDfKv1y7T",
        "outputId": "49907e24-e7ea-4f75-e967-7d94597fa5e3"
      },
      "source": [
        "x_train[800]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This movie packs a punch. There are a few every now and then that make me think deeply, and disturb me a lot. I could see myself in this same predicament - passively allowing things to happen around me, not standing up for the right and decent thing, just trying to avoid trouble. How often do we avoid making waves or sticking our necks out? How often does our inaction condone the evil actions of others. We would never join them, we tell ourselves, we recognize that what they are doing is bad, but do we do anything about it? <br /><br />Lawrence Newman (William H. Macey) is a low-key, nerdy office worker who has paid off his home in Brooklyn, NY in the waning days of World War II. He rarely gets engaged in what is going on around him, has never married, rarely socializes, just goes to work and cares for his invalid mother. Then a series of events in his very \"white\" little neighborhood pull him out of his complacent shell into a maelstrom of events. It starts as he witness from his bedroom window the rape of a Puerto Rican girl by the son of his neighbor. Soon after he gets glasses because of poor vision. As he is now better able to see, he becomes less able to deal with the circumstances of his life. The one bright spot is a new love in his life, and he marries, hoping to continue on in his normalcy. Then the virulent anti-semitism on that street catches him, despite his credentials as a Presbyterian WASP. As things spiral further out of control, he discovers he must make an important decision - does he take a stand or does he simply go away.<br /><br />I cannot how anybody can view this movie without being affected and having to think very much about themselves and what they really stand for. Post war anti-semitism is the setting here, but there is injustice at all times and in all places. It is for the individual to decide where he or she stands.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_CuH6Vd1y7T",
        "outputId": "dfdf60c8-6987-4b1a-ad96-a50c2b3a85d3"
      },
      "source": [
        "y_train[800]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QQhfAHT1y7U"
      },
      "source": [
        "num_words = 10000\n",
        "tokenizer = Tokenizer(num_words=num_words)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbK39Ozx1y7V"
      },
      "source": [
        "tokenizer.fit_on_texts(data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27f6C_3M1y7V",
        "outputId": "78fd99cd-d6fd-4508-bec0-6178538370f9"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'a': 2,\n",
              " 'and': 3,\n",
              " 'of': 4,\n",
              " 'to': 5,\n",
              " 'is': 6,\n",
              " 'br': 7,\n",
              " 'in': 8,\n",
              " 'it': 9,\n",
              " 'i': 10,\n",
              " 'this': 11,\n",
              " 'that': 12,\n",
              " 'was': 13,\n",
              " 'as': 14,\n",
              " 'with': 15,\n",
              " 'for': 16,\n",
              " 'movie': 17,\n",
              " 'but': 18,\n",
              " 'film': 19,\n",
              " 'on': 20,\n",
              " 'not': 21,\n",
              " 'his': 22,\n",
              " 'you': 23,\n",
              " 'are': 24,\n",
              " 'have': 25,\n",
              " 'be': 26,\n",
              " 'one': 27,\n",
              " 'he': 28,\n",
              " 'all': 29,\n",
              " 'by': 30,\n",
              " 'at': 31,\n",
              " 'an': 32,\n",
              " 'they': 33,\n",
              " 'so': 34,\n",
              " 'who': 35,\n",
              " 'from': 36,\n",
              " 'like': 37,\n",
              " 'or': 38,\n",
              " 'just': 39,\n",
              " 'her': 40,\n",
              " 'out': 41,\n",
              " \"it's\": 42,\n",
              " 'if': 43,\n",
              " 'about': 44,\n",
              " 'has': 45,\n",
              " 'there': 46,\n",
              " 'what': 47,\n",
              " 'some': 48,\n",
              " 'good': 49,\n",
              " 'very': 50,\n",
              " 'when': 51,\n",
              " 'more': 52,\n",
              " 'up': 53,\n",
              " 'my': 54,\n",
              " 'even': 55,\n",
              " 'time': 56,\n",
              " 'would': 57,\n",
              " 'no': 58,\n",
              " 'she': 59,\n",
              " 'which': 60,\n",
              " 'their': 61,\n",
              " 'story': 62,\n",
              " 'only': 63,\n",
              " 'really': 64,\n",
              " 'had': 65,\n",
              " 'see': 66,\n",
              " 'me': 67,\n",
              " 'can': 68,\n",
              " 'were': 69,\n",
              " 'well': 70,\n",
              " 'we': 71,\n",
              " 'than': 72,\n",
              " 'much': 73,\n",
              " 'bad': 74,\n",
              " 'been': 75,\n",
              " 'other': 76,\n",
              " 'do': 77,\n",
              " 'great': 78,\n",
              " 'get': 79,\n",
              " 'because': 80,\n",
              " 'first': 81,\n",
              " 'how': 82,\n",
              " 'people': 83,\n",
              " 'him': 84,\n",
              " 'into': 85,\n",
              " \"don't\": 86,\n",
              " 'also': 87,\n",
              " 'will': 88,\n",
              " 'made': 89,\n",
              " 'most': 90,\n",
              " 'its': 91,\n",
              " 'way': 92,\n",
              " 'then': 93,\n",
              " 'them': 94,\n",
              " 'after': 95,\n",
              " 'could': 96,\n",
              " 'any': 97,\n",
              " 'make': 98,\n",
              " 'movies': 99,\n",
              " 'too': 100,\n",
              " 'think': 101,\n",
              " 'characters': 102,\n",
              " 'two': 103,\n",
              " 'watch': 104,\n",
              " 'many': 105,\n",
              " 'character': 106,\n",
              " 'plot': 107,\n",
              " 'films': 108,\n",
              " 'seen': 109,\n",
              " 'being': 110,\n",
              " 'acting': 111,\n",
              " 'never': 112,\n",
              " 'life': 113,\n",
              " 'did': 114,\n",
              " 'best': 115,\n",
              " 'know': 116,\n",
              " 'love': 117,\n",
              " 'show': 118,\n",
              " 'off': 119,\n",
              " 'where': 120,\n",
              " 'little': 121,\n",
              " 'ever': 122,\n",
              " 'over': 123,\n",
              " 'end': 124,\n",
              " 'better': 125,\n",
              " 'scene': 126,\n",
              " 'does': 127,\n",
              " 'your': 128,\n",
              " 'man': 129,\n",
              " 'here': 130,\n",
              " 'these': 131,\n",
              " 'why': 132,\n",
              " 'something': 133,\n",
              " 'such': 134,\n",
              " 'scenes': 135,\n",
              " 'still': 136,\n",
              " 'say': 137,\n",
              " 'while': 138,\n",
              " 'through': 139,\n",
              " 'should': 140,\n",
              " 'go': 141,\n",
              " 'watching': 142,\n",
              " 'now': 143,\n",
              " 'real': 144,\n",
              " 'back': 145,\n",
              " \"i'm\": 146,\n",
              " 'years': 147,\n",
              " 'old': 148,\n",
              " 'another': 149,\n",
              " 'though': 150,\n",
              " 'thing': 151,\n",
              " 'actors': 152,\n",
              " 'nothing': 153,\n",
              " 'those': 154,\n",
              " \"didn't\": 155,\n",
              " \"doesn't\": 156,\n",
              " 'going': 157,\n",
              " 'actually': 158,\n",
              " 'funny': 159,\n",
              " 'makes': 160,\n",
              " 'find': 161,\n",
              " '10': 162,\n",
              " 'before': 163,\n",
              " 'director': 164,\n",
              " 'look': 165,\n",
              " 'work': 166,\n",
              " 'few': 167,\n",
              " 'every': 168,\n",
              " 'new': 169,\n",
              " 'same': 170,\n",
              " 'part': 171,\n",
              " 'lot': 172,\n",
              " 'again': 173,\n",
              " 'want': 174,\n",
              " 'cast': 175,\n",
              " 'pretty': 176,\n",
              " 'quite': 177,\n",
              " 'horror': 178,\n",
              " 'own': 179,\n",
              " 'take': 180,\n",
              " 'however': 181,\n",
              " \"can't\": 182,\n",
              " 'us': 183,\n",
              " 'things': 184,\n",
              " 'fact': 185,\n",
              " 'around': 186,\n",
              " 'world': 187,\n",
              " 'got': 188,\n",
              " 'must': 189,\n",
              " 'seems': 190,\n",
              " 'big': 191,\n",
              " 'thought': 192,\n",
              " 'down': 193,\n",
              " 'both': 194,\n",
              " 'may': 195,\n",
              " 'long': 196,\n",
              " 'without': 197,\n",
              " \"i've\": 198,\n",
              " 'right': 199,\n",
              " 'young': 200,\n",
              " 'action': 201,\n",
              " 'between': 202,\n",
              " 'comedy': 203,\n",
              " 'music': 204,\n",
              " 'interesting': 205,\n",
              " 'give': 206,\n",
              " 'saw': 207,\n",
              " 'enough': 208,\n",
              " 'almost': 209,\n",
              " 'times': 210,\n",
              " \"that's\": 211,\n",
              " 'far': 212,\n",
              " 'whole': 213,\n",
              " 'role': 214,\n",
              " \"isn't\": 215,\n",
              " 'series': 216,\n",
              " 'come': 217,\n",
              " 'minutes': 218,\n",
              " 'always': 219,\n",
              " 'tv': 220,\n",
              " 'gets': 221,\n",
              " 'point': 222,\n",
              " 'each': 223,\n",
              " 'least': 224,\n",
              " 'original': 225,\n",
              " \"there's\": 226,\n",
              " 'might': 227,\n",
              " 'bit': 228,\n",
              " 'done': 229,\n",
              " 'family': 230,\n",
              " 'feel': 231,\n",
              " 'making': 232,\n",
              " 'script': 233,\n",
              " 'anything': 234,\n",
              " 'guy': 235,\n",
              " 'performance': 236,\n",
              " 'yet': 237,\n",
              " 'am': 238,\n",
              " 'sure': 239,\n",
              " 'played': 240,\n",
              " 'kind': 241,\n",
              " 'since': 242,\n",
              " \"he's\": 243,\n",
              " '2': 244,\n",
              " 'probably': 245,\n",
              " 'away': 246,\n",
              " 'hard': 247,\n",
              " 'worst': 248,\n",
              " 'believe': 249,\n",
              " 'anyone': 250,\n",
              " 'fun': 251,\n",
              " 'rather': 252,\n",
              " 'dvd': 253,\n",
              " 'found': 254,\n",
              " 'last': 255,\n",
              " 'book': 256,\n",
              " 'day': 257,\n",
              " 'set': 258,\n",
              " 'shows': 259,\n",
              " 'having': 260,\n",
              " 'looking': 261,\n",
              " 'put': 262,\n",
              " 'our': 263,\n",
              " 'screen': 264,\n",
              " 'course': 265,\n",
              " 'place': 266,\n",
              " 'three': 267,\n",
              " 'girl': 268,\n",
              " 'although': 269,\n",
              " 'woman': 270,\n",
              " 'especially': 271,\n",
              " 'reason': 272,\n",
              " 'trying': 273,\n",
              " 'goes': 274,\n",
              " 'different': 275,\n",
              " 'someone': 276,\n",
              " 'year': 277,\n",
              " 'main': 278,\n",
              " 'play': 279,\n",
              " 'everything': 280,\n",
              " 'war': 281,\n",
              " 'worth': 282,\n",
              " 'once': 283,\n",
              " 'looks': 284,\n",
              " 'plays': 285,\n",
              " 'john': 286,\n",
              " 'maybe': 287,\n",
              " 'job': 288,\n",
              " 'effects': 289,\n",
              " 'watched': 290,\n",
              " 'actor': 291,\n",
              " 'american': 292,\n",
              " 'money': 293,\n",
              " 'together': 294,\n",
              " 'sense': 295,\n",
              " 'version': 296,\n",
              " 'idea': 297,\n",
              " 'half': 298,\n",
              " 'beautiful': 299,\n",
              " 'ending': 300,\n",
              " 'comes': 301,\n",
              " 'high': 302,\n",
              " 'everyone': 303,\n",
              " 'true': 304,\n",
              " 'later': 305,\n",
              " 'takes': 306,\n",
              " 'house': 307,\n",
              " \"wasn't\": 308,\n",
              " 'audience': 309,\n",
              " 'left': 310,\n",
              " 'said': 311,\n",
              " 'himself': 312,\n",
              " 'shot': 313,\n",
              " 'instead': 314,\n",
              " 'wife': 315,\n",
              " 'second': 316,\n",
              " 'special': 317,\n",
              " 'during': 318,\n",
              " 'else': 319,\n",
              " 'seem': 320,\n",
              " 'completely': 321,\n",
              " 'excellent': 322,\n",
              " 'line': 323,\n",
              " 'night': 324,\n",
              " 'seeing': 325,\n",
              " 'simply': 326,\n",
              " 'dead': 327,\n",
              " '1': 328,\n",
              " 'poor': 329,\n",
              " 'either': 330,\n",
              " '3': 331,\n",
              " 'less': 332,\n",
              " 'death': 333,\n",
              " 'father': 334,\n",
              " 'black': 335,\n",
              " 'production': 336,\n",
              " \"you're\": 337,\n",
              " 'use': 338,\n",
              " 'budget': 339,\n",
              " 'star': 340,\n",
              " 'used': 341,\n",
              " 'wrong': 342,\n",
              " 'classic': 343,\n",
              " 'let': 344,\n",
              " 'remember': 345,\n",
              " 'until': 346,\n",
              " 'home': 347,\n",
              " 'enjoy': 348,\n",
              " 'next': 349,\n",
              " 'episode': 350,\n",
              " 'nice': 351,\n",
              " 'wonderful': 352,\n",
              " 'help': 353,\n",
              " 'try': 354,\n",
              " 'boring': 355,\n",
              " 'mind': 356,\n",
              " 'need': 357,\n",
              " 'read': 358,\n",
              " 'start': 359,\n",
              " 'others': 360,\n",
              " 'camera': 361,\n",
              " 'fan': 362,\n",
              " 'came': 363,\n",
              " 'along': 364,\n",
              " 'truly': 365,\n",
              " 'recommend': 366,\n",
              " 'given': 367,\n",
              " 'rest': 368,\n",
              " 'school': 369,\n",
              " 'friends': 370,\n",
              " 'itself': 371,\n",
              " 'terrible': 372,\n",
              " 'called': 373,\n",
              " 'top': 374,\n",
              " 'hollywood': 375,\n",
              " 'full': 376,\n",
              " 'short': 377,\n",
              " 'against': 378,\n",
              " 'often': 379,\n",
              " 'performances': 380,\n",
              " 'sex': 381,\n",
              " 'women': 382,\n",
              " 'title': 383,\n",
              " 'name': 384,\n",
              " 'style': 385,\n",
              " 'low': 386,\n",
              " 'getting': 387,\n",
              " 'understand': 388,\n",
              " 'perhaps': 389,\n",
              " 'keep': 390,\n",
              " 'kids': 391,\n",
              " 'human': 392,\n",
              " 'playing': 393,\n",
              " 'stars': 394,\n",
              " 'video': 395,\n",
              " 'guys': 396,\n",
              " 'boy': 397,\n",
              " 'awful': 398,\n",
              " 'tell': 399,\n",
              " 'moments': 400,\n",
              " '\\x96': 401,\n",
              " 'person': 402,\n",
              " 'men': 403,\n",
              " 'entertaining': 404,\n",
              " 'absolutely': 405,\n",
              " 'face': 406,\n",
              " 'early': 407,\n",
              " 'finally': 408,\n",
              " 'worse': 409,\n",
              " 'gives': 410,\n",
              " 'head': 411,\n",
              " 'couple': 412,\n",
              " 'stupid': 413,\n",
              " 'lines': 414,\n",
              " 'become': 415,\n",
              " 'written': 416,\n",
              " 'definitely': 417,\n",
              " 'game': 418,\n",
              " \"couldn't\": 419,\n",
              " '4': 420,\n",
              " 'mean': 421,\n",
              " 'mother': 422,\n",
              " 'dialogue': 423,\n",
              " 'beginning': 424,\n",
              " 'cinema': 425,\n",
              " 'oh': 426,\n",
              " 'doing': 427,\n",
              " 'lost': 428,\n",
              " 'yes': 429,\n",
              " 'turn': 430,\n",
              " 'case': 431,\n",
              " 'perfect': 432,\n",
              " 'went': 433,\n",
              " 'problem': 434,\n",
              " 'white': 435,\n",
              " 'piece': 436,\n",
              " 'evil': 437,\n",
              " 'dark': 438,\n",
              " 'hope': 439,\n",
              " 'entire': 440,\n",
              " 'sort': 441,\n",
              " 'mr': 442,\n",
              " 'example': 443,\n",
              " 'live': 444,\n",
              " 'small': 445,\n",
              " 'overall': 446,\n",
              " 'art': 447,\n",
              " 'certainly': 448,\n",
              " 'picture': 449,\n",
              " \"she's\": 450,\n",
              " 'children': 451,\n",
              " '5': 452,\n",
              " 'becomes': 453,\n",
              " 'supposed': 454,\n",
              " 'past': 455,\n",
              " 'able': 456,\n",
              " 'direction': 457,\n",
              " 'waste': 458,\n",
              " 'laugh': 459,\n",
              " 'fans': 460,\n",
              " 'final': 461,\n",
              " 'loved': 462,\n",
              " 'days': 463,\n",
              " 'based': 464,\n",
              " 'drama': 465,\n",
              " 'several': 466,\n",
              " 'quality': 467,\n",
              " 'already': 468,\n",
              " 'liked': 469,\n",
              " 'flick': 470,\n",
              " 'guess': 471,\n",
              " 'lead': 472,\n",
              " 'history': 473,\n",
              " 'sound': 474,\n",
              " 'horrible': 475,\n",
              " 'lives': 476,\n",
              " 'despite': 477,\n",
              " 'b': 478,\n",
              " 'felt': 479,\n",
              " 'stuff': 480,\n",
              " 'kill': 481,\n",
              " 'friend': 482,\n",
              " 'eyes': 483,\n",
              " 'city': 484,\n",
              " 'wanted': 485,\n",
              " 'act': 486,\n",
              " 'seemed': 487,\n",
              " 'unfortunately': 488,\n",
              " 'throughout': 489,\n",
              " 'run': 490,\n",
              " 'brilliant': 491,\n",
              " 'themselves': 492,\n",
              " 'town': 493,\n",
              " 'favorite': 494,\n",
              " \"i'd\": 495,\n",
              " 'under': 496,\n",
              " 'fine': 497,\n",
              " 'humor': 498,\n",
              " 'tries': 499,\n",
              " 'writing': 500,\n",
              " 'gave': 501,\n",
              " 'side': 502,\n",
              " 'enjoyed': 503,\n",
              " 'genre': 504,\n",
              " 'care': 505,\n",
              " 'works': 506,\n",
              " \"they're\": 507,\n",
              " 'behind': 508,\n",
              " 'son': 509,\n",
              " 'totally': 510,\n",
              " 'sometimes': 511,\n",
              " 'actress': 512,\n",
              " 'close': 513,\n",
              " 'hour': 514,\n",
              " 'killer': 515,\n",
              " 'turns': 516,\n",
              " 'anyway': 517,\n",
              " 'directed': 518,\n",
              " 'hand': 519,\n",
              " 'myself': 520,\n",
              " 'car': 521,\n",
              " 'amazing': 522,\n",
              " \"you'll\": 523,\n",
              " 'soon': 524,\n",
              " 'viewer': 525,\n",
              " 'blood': 526,\n",
              " 'cannot': 527,\n",
              " 'starts': 528,\n",
              " 'stories': 529,\n",
              " 'heart': 530,\n",
              " 'today': 531,\n",
              " 'parts': 532,\n",
              " 'wants': 533,\n",
              " 'kid': 534,\n",
              " 'decent': 535,\n",
              " 'extremely': 536,\n",
              " 'told': 537,\n",
              " 'killed': 538,\n",
              " 'girls': 539,\n",
              " 'gore': 540,\n",
              " 'looked': 541,\n",
              " 'group': 542,\n",
              " 'happens': 543,\n",
              " 'murder': 544,\n",
              " 'strong': 545,\n",
              " 'took': 546,\n",
              " 'lack': 547,\n",
              " 'expect': 548,\n",
              " 'child': 549,\n",
              " \"won't\": 550,\n",
              " 'known': 551,\n",
              " 'feeling': 552,\n",
              " 'says': 553,\n",
              " 'self': 554,\n",
              " 'fight': 555,\n",
              " 'late': 556,\n",
              " 'coming': 557,\n",
              " 'voice': 558,\n",
              " 'hours': 559,\n",
              " 'including': 560,\n",
              " 'type': 561,\n",
              " 'matter': 562,\n",
              " 'english': 563,\n",
              " 'chance': 564,\n",
              " 'brother': 565,\n",
              " 'etc': 566,\n",
              " 'score': 567,\n",
              " 'experience': 568,\n",
              " 'michael': 569,\n",
              " 'alone': 570,\n",
              " 'career': 571,\n",
              " 'happened': 572,\n",
              " 'moment': 573,\n",
              " 'slow': 574,\n",
              " 'thinking': 575,\n",
              " 'talent': 576,\n",
              " 'shown': 577,\n",
              " 'police': 578,\n",
              " 'seriously': 579,\n",
              " 'daughter': 580,\n",
              " 'hilarious': 581,\n",
              " 'except': 582,\n",
              " 'james': 583,\n",
              " 'particularly': 584,\n",
              " 'interest': 585,\n",
              " 'crap': 586,\n",
              " 'highly': 587,\n",
              " \"wouldn't\": 588,\n",
              " 'happen': 589,\n",
              " 'opening': 590,\n",
              " 'number': 591,\n",
              " 'obviously': 592,\n",
              " 's': 593,\n",
              " 'documentary': 594,\n",
              " 'living': 595,\n",
              " 'finds': 596,\n",
              " 'possible': 597,\n",
              " 'violence': 598,\n",
              " 'ok': 599,\n",
              " 'annoying': 600,\n",
              " 'stop': 601,\n",
              " 'song': 602,\n",
              " 'important': 603,\n",
              " 'writer': 604,\n",
              " 'cut': 605,\n",
              " 'view': 606,\n",
              " 'age': 607,\n",
              " 'obvious': 608,\n",
              " 'hero': 609,\n",
              " 'hit': 610,\n",
              " 'david': 611,\n",
              " 'female': 612,\n",
              " 'leave': 613,\n",
              " 'relationship': 614,\n",
              " 'happy': 615,\n",
              " \"film's\": 616,\n",
              " 'middle': 617,\n",
              " 'songs': 618,\n",
              " 'involved': 619,\n",
              " 'whose': 620,\n",
              " 'heard': 621,\n",
              " 'none': 622,\n",
              " 'ago': 623,\n",
              " 'turned': 624,\n",
              " \"i'll\": 625,\n",
              " 'save': 626,\n",
              " 'body': 627,\n",
              " 'saying': 628,\n",
              " 'word': 629,\n",
              " 'power': 630,\n",
              " 'class': 631,\n",
              " 'upon': 632,\n",
              " 'serious': 633,\n",
              " 'sad': 634,\n",
              " 'british': 635,\n",
              " 'room': 636,\n",
              " 'across': 637,\n",
              " 'opinion': 638,\n",
              " 'modern': 639,\n",
              " 'major': 640,\n",
              " 'hell': 641,\n",
              " 'usually': 642,\n",
              " 'wonder': 643,\n",
              " 'yourself': 644,\n",
              " 'ridiculous': 645,\n",
              " 'events': 646,\n",
              " 'god': 647,\n",
              " 'change': 648,\n",
              " 'cinematography': 649,\n",
              " 'words': 650,\n",
              " 'attempt': 651,\n",
              " 'cool': 652,\n",
              " 'usual': 653,\n",
              " 'knew': 654,\n",
              " 'complete': 655,\n",
              " 'working': 656,\n",
              " 'somewhat': 657,\n",
              " 'due': 658,\n",
              " 'taken': 659,\n",
              " 'thriller': 660,\n",
              " 'rating': 661,\n",
              " 'sequence': 662,\n",
              " 'roles': 663,\n",
              " 'light': 664,\n",
              " \"aren't\": 665,\n",
              " 'mostly': 666,\n",
              " 'cheap': 667,\n",
              " 'mention': 668,\n",
              " 'problems': 669,\n",
              " 'single': 670,\n",
              " 'released': 671,\n",
              " 'exactly': 672,\n",
              " 'novel': 673,\n",
              " 'please': 674,\n",
              " 'simple': 675,\n",
              " 'television': 676,\n",
              " 'bring': 677,\n",
              " 'attention': 678,\n",
              " 'earth': 679,\n",
              " 'beyond': 680,\n",
              " 'french': 681,\n",
              " 'dr': 682,\n",
              " 'episodes': 683,\n",
              " 'running': 684,\n",
              " 'four': 685,\n",
              " 'comments': 686,\n",
              " 'premise': 687,\n",
              " \"'\": 688,\n",
              " 'ones': 689,\n",
              " 'george': 690,\n",
              " 'wish': 691,\n",
              " 'shots': 692,\n",
              " 'local': 693,\n",
              " 'started': 694,\n",
              " 'die': 695,\n",
              " 'message': 696,\n",
              " 'musical': 697,\n",
              " 'appears': 698,\n",
              " 'talk': 699,\n",
              " 'robert': 700,\n",
              " 'sister': 701,\n",
              " 'call': 702,\n",
              " 'huge': 703,\n",
              " '7': 704,\n",
              " 'enjoyable': 705,\n",
              " 'scary': 706,\n",
              " 'strange': 707,\n",
              " 'reality': 708,\n",
              " 'team': 709,\n",
              " 'ways': 710,\n",
              " 'lots': 711,\n",
              " 'taking': 712,\n",
              " 'moving': 713,\n",
              " 'apparently': 714,\n",
              " 'imagine': 715,\n",
              " 'peter': 716,\n",
              " 'theater': 717,\n",
              " 'order': 718,\n",
              " 'whether': 719,\n",
              " 'needs': 720,\n",
              " 'silly': 721,\n",
              " 'husband': 722,\n",
              " 'level': 723,\n",
              " 'non': 724,\n",
              " 'clearly': 725,\n",
              " 'ends': 726,\n",
              " 'straight': 727,\n",
              " 'dialog': 728,\n",
              " 'predictable': 729,\n",
              " 'nearly': 730,\n",
              " 'crime': 731,\n",
              " 'knows': 732,\n",
              " 'release': 733,\n",
              " 'editing': 734,\n",
              " 'king': 735,\n",
              " 'clear': 736,\n",
              " 'paul': 737,\n",
              " 'bunch': 738,\n",
              " 'among': 739,\n",
              " 'monster': 740,\n",
              " 'ten': 741,\n",
              " 'falls': 742,\n",
              " 'filmed': 743,\n",
              " 'believable': 744,\n",
              " 'sets': 745,\n",
              " 'romantic': 746,\n",
              " 't': 747,\n",
              " 'surprised': 748,\n",
              " 'effort': 749,\n",
              " 'soundtrack': 750,\n",
              " 'sequel': 751,\n",
              " 'disappointed': 752,\n",
              " 'york': 753,\n",
              " 'review': 754,\n",
              " 'tried': 755,\n",
              " 'tells': 756,\n",
              " 'difficult': 757,\n",
              " 'richard': 758,\n",
              " 'jack': 759,\n",
              " 'points': 760,\n",
              " '20': 761,\n",
              " 'forget': 762,\n",
              " 'named': 763,\n",
              " 'oscar': 764,\n",
              " 'gone': 765,\n",
              " 'shame': 766,\n",
              " 'talking': 767,\n",
              " 'feature': 768,\n",
              " 'above': 769,\n",
              " 'famous': 770,\n",
              " 'elements': 771,\n",
              " 'sorry': 772,\n",
              " 'period': 773,\n",
              " 'actual': 774,\n",
              " 'near': 775,\n",
              " \"you've\": 776,\n",
              " 'animation': 777,\n",
              " 'easily': 778,\n",
              " 'entertainment': 779,\n",
              " 'dull': 780,\n",
              " 'gay': 781,\n",
              " 'typical': 782,\n",
              " 'add': 783,\n",
              " 'basically': 784,\n",
              " 'similar': 785,\n",
              " 'certain': 786,\n",
              " 'mystery': 787,\n",
              " 'cop': 788,\n",
              " 'weak': 789,\n",
              " 'hate': 790,\n",
              " 'follow': 791,\n",
              " '8': 792,\n",
              " 'fantastic': 793,\n",
              " 'five': 794,\n",
              " 'plus': 795,\n",
              " 'eventually': 796,\n",
              " 'within': 797,\n",
              " 'supporting': 798,\n",
              " 'average': 799,\n",
              " 'kept': 800,\n",
              " 'open': 801,\n",
              " 'interested': 802,\n",
              " 'using': 803,\n",
              " 'viewing': 804,\n",
              " 'showing': 805,\n",
              " 'comic': 806,\n",
              " 'imdb': 807,\n",
              " 'stand': 808,\n",
              " 'hands': 809,\n",
              " 'jokes': 810,\n",
              " 'parents': 811,\n",
              " 'miss': 812,\n",
              " 'material': 813,\n",
              " 'minute': 814,\n",
              " 'country': 815,\n",
              " 'buy': 816,\n",
              " 'form': 817,\n",
              " \"haven't\": 818,\n",
              " 'realistic': 819,\n",
              " 'somehow': 820,\n",
              " 'suspense': 821,\n",
              " 'season': 822,\n",
              " 'sit': 823,\n",
              " 'needed': 824,\n",
              " 'easy': 825,\n",
              " 'whom': 826,\n",
              " 'directors': 827,\n",
              " 'future': 828,\n",
              " 'dance': 829,\n",
              " 'means': 830,\n",
              " 'rock': 831,\n",
              " 'move': 832,\n",
              " 'rent': 833,\n",
              " 'feels': 834,\n",
              " 'truth': 835,\n",
              " 'lady': 836,\n",
              " 'poorly': 837,\n",
              " 'became': 838,\n",
              " 'tom': 839,\n",
              " 'space': 840,\n",
              " 'towards': 841,\n",
              " 'okay': 842,\n",
              " 'free': 843,\n",
              " 'crew': 844,\n",
              " 'present': 845,\n",
              " 'storyline': 846,\n",
              " 'sequences': 847,\n",
              " 'greatest': 848,\n",
              " 'deal': 849,\n",
              " 'avoid': 850,\n",
              " 'expected': 851,\n",
              " '9': 852,\n",
              " 'doctor': 853,\n",
              " 'water': 854,\n",
              " 'perfectly': 855,\n",
              " 'leaves': 856,\n",
              " 'reviews': 857,\n",
              " 'figure': 858,\n",
              " 'brought': 859,\n",
              " 'sexual': 860,\n",
              " 'check': 861,\n",
              " \"who's\": 862,\n",
              " 'general': 863,\n",
              " 'learn': 864,\n",
              " 'possibly': 865,\n",
              " 'office': 866,\n",
              " 'herself': 867,\n",
              " 'subject': 868,\n",
              " 'various': 869,\n",
              " 'male': 870,\n",
              " 'tale': 871,\n",
              " 'hear': 872,\n",
              " 'lee': 873,\n",
              " 'earlier': 874,\n",
              " 'cute': 875,\n",
              " 'society': 876,\n",
              " 'doubt': 877,\n",
              " \"what's\": 878,\n",
              " 'giving': 879,\n",
              " 'directing': 880,\n",
              " 'secret': 881,\n",
              " 'question': 882,\n",
              " 'result': 883,\n",
              " 'masterpiece': 884,\n",
              " 'personal': 885,\n",
              " 're': 886,\n",
              " 'surprise': 887,\n",
              " 'box': 888,\n",
              " 'theme': 889,\n",
              " 'lame': 890,\n",
              " 'wasted': 891,\n",
              " 'footage': 892,\n",
              " 'brings': 893,\n",
              " 'note': 894,\n",
              " 'red': 895,\n",
              " 'beauty': 896,\n",
              " 'fast': 897,\n",
              " 'fi': 898,\n",
              " 'hot': 899,\n",
              " 'romance': 900,\n",
              " 'nature': 901,\n",
              " 'whatever': 902,\n",
              " 'eye': 903,\n",
              " 'sci': 904,\n",
              " 'baby': 905,\n",
              " 'crazy': 906,\n",
              " 'portrayed': 907,\n",
              " \"we're\": 908,\n",
              " 'japanese': 909,\n",
              " 'unless': 910,\n",
              " 'street': 911,\n",
              " 'e': 912,\n",
              " 'german': 913,\n",
              " 'fall': 914,\n",
              " 'previous': 915,\n",
              " 'screenplay': 916,\n",
              " 'older': 917,\n",
              " 'leading': 918,\n",
              " 'mess': 919,\n",
              " 'viewers': 920,\n",
              " 'battle': 921,\n",
              " 'de': 922,\n",
              " 'stay': 923,\n",
              " 'superb': 924,\n",
              " 'dog': 925,\n",
              " 'girlfriend': 926,\n",
              " 'wrote': 927,\n",
              " 'wait': 928,\n",
              " 'writers': 929,\n",
              " 'inside': 930,\n",
              " 'development': 931,\n",
              " 'nor': 932,\n",
              " 'credits': 933,\n",
              " 'air': 934,\n",
              " 'stage': 935,\n",
              " 'pay': 936,\n",
              " 'leads': 937,\n",
              " 'forced': 938,\n",
              " 'boys': 939,\n",
              " 'begin': 940,\n",
              " 'rate': 941,\n",
              " 'comment': 942,\n",
              " 'sam': 943,\n",
              " 'casting': 944,\n",
              " 'indeed': 945,\n",
              " 'features': 946,\n",
              " 'memorable': 947,\n",
              " 'decided': 948,\n",
              " 'villain': 949,\n",
              " 'incredibly': 950,\n",
              " 'fire': 951,\n",
              " 'manages': 952,\n",
              " 'telling': 953,\n",
              " 'fantasy': 954,\n",
              " 'weird': 955,\n",
              " 'remake': 956,\n",
              " \"'the\": 957,\n",
              " 'forward': 958,\n",
              " 'particular': 959,\n",
              " 'cold': 960,\n",
              " 'steve': 961,\n",
              " 'keeps': 962,\n",
              " 'compared': 963,\n",
              " 'quickly': 964,\n",
              " 'atmosphere': 965,\n",
              " 'following': 966,\n",
              " 'spirit': 967,\n",
              " 'begins': 968,\n",
              " 'era': 969,\n",
              " 'clever': 970,\n",
              " 'members': 971,\n",
              " 'considering': 972,\n",
              " 'otherwise': 973,\n",
              " 'plenty': 974,\n",
              " \"let's\": 975,\n",
              " 'fighting': 976,\n",
              " 'filmmakers': 977,\n",
              " 'mark': 978,\n",
              " 'filled': 979,\n",
              " 'co': 980,\n",
              " 'reading': 981,\n",
              " 'front': 982,\n",
              " 'copy': 983,\n",
              " 'follows': 984,\n",
              " 'emotional': 985,\n",
              " 'western': 986,\n",
              " 'setting': 987,\n",
              " 'acted': 988,\n",
              " 'killing': 989,\n",
              " 'total': 990,\n",
              " 'credit': 991,\n",
              " 'bill': 992,\n",
              " 'create': 993,\n",
              " 'dumb': 994,\n",
              " 'deep': 995,\n",
              " 'expecting': 996,\n",
              " '15': 997,\n",
              " 'appear': 998,\n",
              " 'deserves': 999,\n",
              " 'effect': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I99GvnUr1y7W"
      },
      "source": [
        "x_train_tokens = tokenizer.texts_to_sequences(x_train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "EkLND4GP1y7X",
        "outputId": "6a5220a9-e05c-4eb6-c645-824951753499"
      },
      "source": [
        "x_train[800]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This movie packs a punch. There are a few every now and then that make me think deeply, and disturb me a lot. I could see myself in this same predicament - passively allowing things to happen around me, not standing up for the right and decent thing, just trying to avoid trouble. How often do we avoid making waves or sticking our necks out? How often does our inaction condone the evil actions of others. We would never join them, we tell ourselves, we recognize that what they are doing is bad, but do we do anything about it? <br /><br />Lawrence Newman (William H. Macey) is a low-key, nerdy office worker who has paid off his home in Brooklyn, NY in the waning days of World War II. He rarely gets engaged in what is going on around him, has never married, rarely socializes, just goes to work and cares for his invalid mother. Then a series of events in his very \"white\" little neighborhood pull him out of his complacent shell into a maelstrom of events. It starts as he witness from his bedroom window the rape of a Puerto Rican girl by the son of his neighbor. Soon after he gets glasses because of poor vision. As he is now better able to see, he becomes less able to deal with the circumstances of his life. The one bright spot is a new love in his life, and he marries, hoping to continue on in his normalcy. Then the virulent anti-semitism on that street catches him, despite his credentials as a Presbyterian WASP. As things spiral further out of control, he discovers he must make an important decision - does he take a stand or does he simply go away.<br /><br />I cannot how anybody can view this movie without being affected and having to think very much about themselves and what they really stand for. Post war anti-semitism is the setting here, but there is injustice at all times and in all places. It is for the individual to decide where he or she stands.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAfzMRpl1y7X",
        "outputId": "63e1a219-d213-4495-eaef-3dc08a02933a"
      },
      "source": [
        "print(x_train_tokens[800])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11, 17, 7401, 2, 3217, 46, 24, 2, 167, 168, 143, 3, 93, 12, 98, 67, 101, 1410, 3, 67, 2, 172, 10, 96, 66, 520, 8, 11, 170, 7910, 2869, 184, 5, 589, 186, 67, 21, 2135, 53, 16, 1, 199, 3, 535, 151, 39, 273, 5, 850, 1318, 82, 379, 77, 71, 850, 232, 4572, 38, 7938, 263, 41, 82, 379, 127, 263, 1, 437, 1671, 4, 360, 71, 57, 112, 3231, 94, 71, 399, 2937, 71, 2828, 12, 47, 33, 24, 427, 6, 74, 18, 77, 71, 77, 234, 44, 9, 7, 7, 3972, 6901, 1093, 3097, 6, 2, 386, 1233, 866, 3248, 35, 45, 1471, 119, 22, 347, 8, 6254, 9492, 8, 1, 463, 4, 187, 281, 1470, 28, 1640, 221, 5338, 8, 47, 6, 157, 20, 186, 84, 45, 112, 1328, 1640, 39, 274, 5, 166, 3, 2012, 16, 22, 422, 93, 2, 216, 4, 646, 8, 22, 50, 435, 121, 3206, 1382, 84, 41, 4, 22, 5811, 85, 2, 4, 646, 9, 528, 14, 28, 1986, 36, 22, 5741, 1866, 1, 1761, 4, 2, 6929, 8652, 268, 30, 1, 509, 4, 22, 3343, 524, 95, 28, 221, 3931, 80, 4, 329, 1841, 14, 28, 6, 143, 125, 456, 5, 66, 28, 453, 332, 456, 5, 849, 15, 1, 2284, 4, 22, 113, 1, 27, 1655, 1538, 6, 2, 169, 117, 8, 22, 113, 3, 28, 9309, 1293, 5, 1767, 20, 8, 22, 93, 1, 1363, 9081, 20, 12, 911, 3424, 84, 477, 22, 8981, 14, 2, 14, 184, 6139, 1016, 41, 4, 1055, 28, 2217, 28, 189, 98, 32, 603, 2103, 127, 28, 180, 2, 808, 38, 127, 28, 326, 141, 246, 7, 7, 10, 527, 82, 1791, 68, 606, 11, 17, 197, 110, 4523, 3, 260, 5, 101, 50, 73, 44, 492, 3, 47, 33, 64, 808, 16, 1232, 281, 1363, 9081, 6, 1, 987, 130, 18, 46, 6, 8020, 31, 29, 210, 3, 8, 29, 1244, 9, 6, 16, 1, 2035, 5, 1201, 120, 28, 38, 59, 1302]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjJebxB11y7Y"
      },
      "source": [
        "x_test_tokens = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxsl-vha1y7Y"
      },
      "source": [
        "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
        "num_tokens = np.array(num_tokens)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1VnjVBp1y7Z",
        "outputId": "e239da1b-785e-4083-9345-b8cea7f02200"
      },
      "source": [
        "np.mean(num_tokens)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222.677"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSsjfcyZ1y7Z",
        "outputId": "2bad794b-83ea-46c9-9482-c2013d6db70b"
      },
      "source": [
        "np.max(num_tokens)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHJw2c2X1y7a",
        "outputId": "8b8f54a8-5d2d-43b5-f510-49cc70e82efa"
      },
      "source": [
        "np.argmax(num_tokens)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2510"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "_bP42AQC1y7b",
        "outputId": "f38ecfe1-1de0-4a69-97ff-4235ff537612"
      },
      "source": [
        "x_train[2194]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"A warmly sentimental tale from the author of The Waltons. Were someone to pitch the material to me, I would probably reject it as too maudlin. But the dramatization here manages a tear without the expected embarrassment. No one in the 1950's was better at lovable hayseeds than Arthur Hunnicutt. His appeal here is put to consummate use as a mountain man doggedly faithful to a loyal hunting hound. Their fates are tied together as inseparably as any human bond. Good. I see a subtle environmental message here. All critters go to heaven, because how can we condemn any poor devil that merely follows instinct in order to stay alive. There is no deceit in the kingdom of animals, and yet how cruelly we often treat them. An oddly satisfying episode that confirms this important message.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuaBzxf-1y7b",
        "outputId": "9d234274-d352-4755-d5d6-c511fe652a6f"
      },
      "source": [
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "554"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQK7RGh11y7c",
        "outputId": "1ce7b652-cb30-4cb9-9445-a9feb23822e5"
      },
      "source": [
        "np.sum(num_tokens < max_tokens) / len(num_tokens)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8J50STT1y7c"
      },
      "source": [
        "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYX_HzPj1y7d"
      },
      "source": [
        "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Jn1ba51y7d",
        "outputId": "b09e994c-f925-4b8c-f371-2cbcd006e9ee"
      },
      "source": [
        "x_train_pad.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 554)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAox3OIj1y7e",
        "outputId": "7337d9d7-9577-4afb-e6be-925d4ef3b0ab"
      },
      "source": [
        "x_test_pad.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 554)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km7D0D5j1y7f",
        "outputId": "510f0516-956e-46f4-e616-f28e5c74ec45"
      },
      "source": [
        "np.array(x_train_tokens[800])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  11,   17, 7401,    2, 3217,   46,   24,    2,  167,  168,  143,\n",
              "          3,   93,   12,   98,   67,  101, 1410,    3,   67,    2,  172,\n",
              "         10,   96,   66,  520,    8,   11,  170, 7910, 2869,  184,    5,\n",
              "        589,  186,   67,   21, 2135,   53,   16,    1,  199,    3,  535,\n",
              "        151,   39,  273,    5,  850, 1318,   82,  379,   77,   71,  850,\n",
              "        232, 4572,   38, 7938,  263,   41,   82,  379,  127,  263,    1,\n",
              "        437, 1671,    4,  360,   71,   57,  112, 3231,   94,   71,  399,\n",
              "       2937,   71, 2828,   12,   47,   33,   24,  427,    6,   74,   18,\n",
              "         77,   71,   77,  234,   44,    9,    7,    7, 3972, 6901, 1093,\n",
              "       3097,    6,    2,  386, 1233,  866, 3248,   35,   45, 1471,  119,\n",
              "         22,  347,    8, 6254, 9492,    8,    1,  463,    4,  187,  281,\n",
              "       1470,   28, 1640,  221, 5338,    8,   47,    6,  157,   20,  186,\n",
              "         84,   45,  112, 1328, 1640,   39,  274,    5,  166,    3, 2012,\n",
              "         16,   22,  422,   93,    2,  216,    4,  646,    8,   22,   50,\n",
              "        435,  121, 3206, 1382,   84,   41,    4,   22, 5811,   85,    2,\n",
              "          4,  646,    9,  528,   14,   28, 1986,   36,   22, 5741, 1866,\n",
              "          1, 1761,    4,    2, 6929, 8652,  268,   30,    1,  509,    4,\n",
              "         22, 3343,  524,   95,   28,  221, 3931,   80,    4,  329, 1841,\n",
              "         14,   28,    6,  143,  125,  456,    5,   66,   28,  453,  332,\n",
              "        456,    5,  849,   15,    1, 2284,    4,   22,  113,    1,   27,\n",
              "       1655, 1538,    6,    2,  169,  117,    8,   22,  113,    3,   28,\n",
              "       9309, 1293,    5, 1767,   20,    8,   22,   93,    1, 1363, 9081,\n",
              "         20,   12,  911, 3424,   84,  477,   22, 8981,   14,    2,   14,\n",
              "        184, 6139, 1016,   41,    4, 1055,   28, 2217,   28,  189,   98,\n",
              "         32,  603, 2103,  127,   28,  180,    2,  808,   38,  127,   28,\n",
              "        326,  141,  246,    7,    7,   10,  527,   82, 1791,   68,  606,\n",
              "         11,   17,  197,  110, 4523,    3,  260,    5,  101,   50,   73,\n",
              "         44,  492,    3,   47,   33,   64,  808,   16, 1232,  281, 1363,\n",
              "       9081,    6,    1,  987,  130,   18,   46,    6, 8020,   31,   29,\n",
              "        210,    3,    8,   29, 1244,    9,    6,   16,    1, 2035,    5,\n",
              "       1201,  120,   28,   38,   59, 1302])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVGvlYAA1y7g",
        "outputId": "dcf08d88-0ece-408a-e14d-f90ecba0b931"
      },
      "source": [
        "x_train_pad[800]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,   11,   17,\n",
              "       7401,    2, 3217,   46,   24,    2,  167,  168,  143,    3,   93,\n",
              "         12,   98,   67,  101, 1410,    3,   67,    2,  172,   10,   96,\n",
              "         66,  520,    8,   11,  170, 7910, 2869,  184,    5,  589,  186,\n",
              "         67,   21, 2135,   53,   16,    1,  199,    3,  535,  151,   39,\n",
              "        273,    5,  850, 1318,   82,  379,   77,   71,  850,  232, 4572,\n",
              "         38, 7938,  263,   41,   82,  379,  127,  263,    1,  437, 1671,\n",
              "          4,  360,   71,   57,  112, 3231,   94,   71,  399, 2937,   71,\n",
              "       2828,   12,   47,   33,   24,  427,    6,   74,   18,   77,   71,\n",
              "         77,  234,   44,    9,    7,    7, 3972, 6901, 1093, 3097,    6,\n",
              "          2,  386, 1233,  866, 3248,   35,   45, 1471,  119,   22,  347,\n",
              "          8, 6254, 9492,    8,    1,  463,    4,  187,  281, 1470,   28,\n",
              "       1640,  221, 5338,    8,   47,    6,  157,   20,  186,   84,   45,\n",
              "        112, 1328, 1640,   39,  274,    5,  166,    3, 2012,   16,   22,\n",
              "        422,   93,    2,  216,    4,  646,    8,   22,   50,  435,  121,\n",
              "       3206, 1382,   84,   41,    4,   22, 5811,   85,    2,    4,  646,\n",
              "          9,  528,   14,   28, 1986,   36,   22, 5741, 1866,    1, 1761,\n",
              "          4,    2, 6929, 8652,  268,   30,    1,  509,    4,   22, 3343,\n",
              "        524,   95,   28,  221, 3931,   80,    4,  329, 1841,   14,   28,\n",
              "          6,  143,  125,  456,    5,   66,   28,  453,  332,  456,    5,\n",
              "        849,   15,    1, 2284,    4,   22,  113,    1,   27, 1655, 1538,\n",
              "          6,    2,  169,  117,    8,   22,  113,    3,   28, 9309, 1293,\n",
              "          5, 1767,   20,    8,   22,   93,    1, 1363, 9081,   20,   12,\n",
              "        911, 3424,   84,  477,   22, 8981,   14,    2,   14,  184, 6139,\n",
              "       1016,   41,    4, 1055,   28, 2217,   28,  189,   98,   32,  603,\n",
              "       2103,  127,   28,  180,    2,  808,   38,  127,   28,  326,  141,\n",
              "        246,    7,    7,   10,  527,   82, 1791,   68,  606,   11,   17,\n",
              "        197,  110, 4523,    3,  260,    5,  101,   50,   73,   44,  492,\n",
              "          3,   47,   33,   64,  808,   16, 1232,  281, 1363, 9081,    6,\n",
              "          1,  987,  130,   18,   46,    6, 8020,   31,   29,  210,    3,\n",
              "          8,   29, 1244,    9,    6,   16,    1, 2035,    5, 1201,  120,\n",
              "         28,   38,   59, 1302], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43gPfyHk1y7h"
      },
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjTmo8Ot1y7h"
      },
      "source": [
        "def tokens_to_string(tokens):\n",
        "    words = [inverse_map[token] for token in tokens if token!=0]\n",
        "    text = ' '.join(words)\n",
        "    return text"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "0PtZ_47O1y7i",
        "outputId": "92333944-66d1-4cd7-8947-d798a96f38d3"
      },
      "source": [
        "x_train[800]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This movie packs a punch. There are a few every now and then that make me think deeply, and disturb me a lot. I could see myself in this same predicament - passively allowing things to happen around me, not standing up for the right and decent thing, just trying to avoid trouble. How often do we avoid making waves or sticking our necks out? How often does our inaction condone the evil actions of others. We would never join them, we tell ourselves, we recognize that what they are doing is bad, but do we do anything about it? <br /><br />Lawrence Newman (William H. Macey) is a low-key, nerdy office worker who has paid off his home in Brooklyn, NY in the waning days of World War II. He rarely gets engaged in what is going on around him, has never married, rarely socializes, just goes to work and cares for his invalid mother. Then a series of events in his very \"white\" little neighborhood pull him out of his complacent shell into a maelstrom of events. It starts as he witness from his bedroom window the rape of a Puerto Rican girl by the son of his neighbor. Soon after he gets glasses because of poor vision. As he is now better able to see, he becomes less able to deal with the circumstances of his life. The one bright spot is a new love in his life, and he marries, hoping to continue on in his normalcy. Then the virulent anti-semitism on that street catches him, despite his credentials as a Presbyterian WASP. As things spiral further out of control, he discovers he must make an important decision - does he take a stand or does he simply go away.<br /><br />I cannot how anybody can view this movie without being affected and having to think very much about themselves and what they really stand for. Post war anti-semitism is the setting here, but there is injustice at all times and in all places. It is for the individual to decide where he or she stands.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "enF8B4L-1y7i",
        "outputId": "c3a5b25d-c8c3-4f5f-e955-e5e19fd33e4b"
      },
      "source": [
        "tokens_to_string(x_train_tokens[800])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this movie packs a punch there are a few every now and then that make me think deeply and me a lot i could see myself in this same predicament allowing things to happen around me not standing up for the right and decent thing just trying to avoid trouble how often do we avoid making waves or sticking our out how often does our the evil actions of others we would never join them we tell ourselves we recognize that what they are doing is bad but do we do anything about it br br lawrence newman william h is a low key office worker who has paid off his home in brooklyn ny in the days of world war ii he rarely gets engaged in what is going on around him has never married rarely just goes to work and cares for his mother then a series of events in his very white little neighborhood pull him out of his shell into a of events it starts as he witness from his bedroom window the rape of a puerto rican girl by the son of his neighbor soon after he gets glasses because of poor vision as he is now better able to see he becomes less able to deal with the circumstances of his life the one bright spot is a new love in his life and he marries hoping to continue on in his then the anti semitism on that street catches him despite his credentials as a as things spiral further out of control he discovers he must make an important decision does he take a stand or does he simply go away br br i cannot how anybody can view this movie without being affected and having to think very much about themselves and what they really stand for post war anti semitism is the setting here but there is injustice at all times and in all places it is for the individual to decide where he or she stands'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-a14-OK1y7j"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrNd4UQA1y7j"
      },
      "source": [
        "embedding_size = 50"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj03tbyP1y7j"
      },
      "source": [
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='embedding_layer'))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42X2SudI1y7k"
      },
      "source": [
        "model.add(GRU(units=16, return_sequences=True))\n",
        "model.add(GRU(units=8, return_sequences=True))\n",
        "model.add(GRU(units=4))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "wiq4x4Gr1y7k",
        "outputId": "f9ed7892-1759-4782-fbe0-078383be7365"
      },
      "source": [
        "#optimizer = Adam(lr=1e-3)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-637dde4c6b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Q-Fa5mEy1y7l",
        "outputId": "2b5c6653-d3b6-40a8-9f68-9b36b91613f3"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-c3638a237d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(loss='binary_crossentropy',\n\u001b[0;32m----> 2\u001b[0;31m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SXCvXdP1y7l",
        "outputId": "fc64bf37-7107-43e4-b455-8557aecfde57"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_layer (Embedding)  (None, 554, 50)           500000    \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 554, 16)           3216      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 554, 8)            600       \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 4)                 156       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 503,977\n",
            "Trainable params: 503,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "GFT_wlhN1y7m",
        "outputId": "8d337af0-ab99-4773-9846-f3fc1d979ea1"
      },
      "source": [
        "model.fit(x_train_pad, y_train, epochs=5, batch_size=256)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-631bbf0ac3a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2592\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2593\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "NaBPxmbb1y7m",
        "outputId": "c105b011-6215-4105-f480-a789eb410cce"
      },
      "source": [
        "result = model.evaluate(x_test_pad, y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-eaaf3ba1d1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0mbase_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2592\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2593\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "BvNN508a1y7n",
        "outputId": "55ef8c95-a590-46f1-db43-8a567e4af58c"
      },
      "source": [
        "result[1]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-7b02dd6b597f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZVfvrir1y7o"
      },
      "source": [
        "y_pred = model.predict(x=x_test_pad[0:1000])\n",
        "y_pred = y_pred.T[0]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXnPcwtH1y7o"
      },
      "source": [
        "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjYL1MgF1y7o"
      },
      "source": [
        "cls_true = np.array(y_test[0:1000])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN3ztwJ01y7p"
      },
      "source": [
        "incorrect = np.where(cls_pred != cls_true)\n",
        "incorrect = incorrect[0]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxVEk0Tu1y7p",
        "outputId": "395c7d7c-7e24-41ee-a395-b3cb7a157569"
      },
      "source": [
        "len(incorrect)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "508"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTQNDzSs1y7q",
        "outputId": "9580bb09-17d2-44bd-ecc4-6b84c0222616"
      },
      "source": [
        "idx = incorrect[0]\n",
        "idx"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "8tzz3qi41y7q",
        "outputId": "e7f2214e-080f-427f-8f0f-377d212e77e1"
      },
      "source": [
        "text = x_test[idx]\n",
        "text"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(SPOILERS IN FIRST PARAGRAPH) This movie\\'s anti-German sentiment seems painfully dated now, but it\\'s a brilliant example of great war-time propaganda. It was made back when Cecil B. DeMille was still a great director. (Ignore all his later Best Picture Academy Awards; he never made a very good sound film.) This movie lacks the comedy of most of Pickford\\'s other films, and really it was DeMille\\'s movie, not Pickford\\'s. The vilification of the Germans can be compared to the way \"The Patriot\" of 2000 did the same to the British. The only good German in the film was a reluctant villain who had the ironic name of Austreheim. They even had Pickford take an ill-fated trip on a luxury ship that gets torpedoed by a German submarine. So what\\'ll get the Americans more stirred up to war? The sinking of the Lusitania, or watching America\\'s favorite Canadian import sinking in it? All throughout the film DeMille runs his protagonist from one kind of horrible calamity to another, barely escaping death, hypothermia, depravity, rape, execution, and explosions that go off in just the right place to keep her unharmed. The way she is saved from a firing squad is no more believable than the way the humans in \"Jurassic Park\" were ultimately rescued from the velociraptors. If I was any more gullible to such propaganda I would punish myself for having a part-German ancestry. <br /><br />Was it a good film? Aside from a humorous running gag about Americans abroad thinking they\\'re untouchable \\x96 that was apparently a joke even back then \\x96 you might not be entertained. You\\'ll find it more than a little melodramatic, and obviously one-sided, but the first thing that came to my mind after watching it is that it was years before Potemkin\\'s false portrayal of a massacre revolutionized the language of cinema as well as a movie\\'s potential for propaganda. It made me wonder: what became of Cecil B. DeMille? Somewhere between the advent of sound and \"The Greatest Show on Earth\" he seemed to lose his ambition. Ben Hur looked expensive, but not ambitious. In a sentence, this movie is for 1) Film historians, 2) Silent Film Buffs, 3) Mary Pickford fans, or 4) DeMille fans, if such a person exists.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvTUP8_m1y7r",
        "outputId": "402ecdc7-4354-4d0e-be4b-01914c19679f"
      },
      "source": [
        "y_pred[idx]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4966992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nJxqV9D1y7r",
        "outputId": "6843216f-52ed-44a0-9061-d56ac331655e"
      },
      "source": [
        "cls_true[idx]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQlgj0jj1y7s"
      },
      "source": [
        "text1 = \"bu Ã¼rÃ¼n Ã§ok iyi herkese tavsiye ederim\"\n",
        "text2 = \"kargo Ã§ok hÄ±zlÄ± aynÄ± gÃ¼n elime geÃ§ti\"\n",
        "text3 = \"bÃ¼yÃ¼k bir hayal kÄ±rÄ±klÄ±ÄŸÄ± yaÅŸadÄ±m bu Ã¼rÃ¼n bu markaya yakÄ±ÅŸmamÄ±ÅŸ\"\n",
        "text4 = \"mÃ¼kemmel\"\n",
        "text5 = \"tasarÄ±mÄ± harika ancak kargo Ã§ok geÃ§ geldi ve Ã¼rÃ¼n aÃ§Ä±lmÄ±ÅŸtÄ± tavsiye etmem\"\n",
        "text6 = \"hiÃ§ resimde gÃ¶sterildiÄŸi gibi deÄŸil\"\n",
        "text7 = \"kÃ¶tÃ¼ yorumlar gÃ¶zÃ¼mÃ¼ korkutmuÅŸtu ancak hiÃ§bir sorun yaÅŸamadÄ±m teÅŸekkÃ¼rler\"\n",
        "text8 = \"hiÃ§ bu kadar kÃ¶tÃ¼ bir satÄ±cÄ±ya denk gelmemiÅŸtim Ã¼rÃ¼nÃ¼ geri iade ediyorum\"\n",
        "text9 = \"tam bir fiyat performans Ã¼rÃ¼nÃ¼\"\n",
        "text10 = \"beklediÄŸim gibi Ã§Ä±kmadÄ±\"\n",
        "texts = [text1, text2, text3, text4, text5, text6, text7, text8, text9, text10]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0PwVfkQ1y7t"
      },
      "source": [
        "tokens = tokenizer.texts_to_sequences(texts)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo9vewzq1y7t",
        "outputId": "4172952a-35b2-4a0e-9e6b-98198436b9c6"
      },
      "source": [
        "tokens_pad = pad_sequences(tokens, maxlen=max_tokens)\n",
        "tokens_pad.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 554)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU7z-1uT1y7u",
        "outputId": "fc27f1d4-4d0c-4e68-ec8a-3ee34174b8ba"
      },
      "source": [
        "model.predict(tokens_pad)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5030463],\n",
              "       [0.5030463],\n",
              "       [0.5030463],\n",
              "       [0.5030463],\n",
              "       [0.5030463],\n",
              "       [0.5030463],\n",
              "       [0.5030463],\n",
              "       [0.5030463],\n",
              "       [0.5030463],\n",
              "       [0.5030463]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-o9FZgX1y7u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}